{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "- Use Gutenberg and Web_text data. Find out what are the top 5 words that Shakespeare used but we do not use in currently.\n",
    "- Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records).\n",
    "- Remove punctuation and stop words.\n",
    "- Remove the words we still use today, and get the unused list. Show the top 5 elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_ss = []\n",
    "words_ss.extend(nltk.corpus.gutenberg.words('shakespeare-caesar.txt'))\n",
    "words_ss.extend(nltk.corpus.gutenberg.words('shakespeare-hamlet.txt'))\n",
    "words_ss.extend(nltk.corpus.gutenberg.words('shakespeare-macbeth.txt'))\n",
    "#type(words_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_ss = [''.join(c for c in s if c not in set(string.punctuation)) for s in words_ss]   #remove all punctuation words\n",
    "words_ss = [x for x in words_ss if x]                                                      #remove epmty string from list of words\n",
    "\n",
    "words_ss_lower = []\n",
    "for word in words_ss:\n",
    "    words_ss_lower.append(word.lower())  #convert all the words in lower case\n",
    "\n",
    "words_ss_lower = [word for word in words_ss_lower if word not in stopwords.words('english')] #remove all stop words\n",
    "\n",
    "words_ss_freq = {}\n",
    "for word in words_ss_lower:              #loop through each word \n",
    "    if word in words_ss_freq:\n",
    "        words_ss_freq[word] += 1\n",
    "    else:\n",
    "        words_ss_freq[word] = 1\n",
    "#print(words_ss_freq)\n",
    "listOfSortedWords = []                                                           \n",
    "listOfSortedWords = sorted(words_ss_freq, key=words_ss_freq.__getitem__ , reverse= True) #sorting words in descending order based on frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 words in Shakespeare: \n",
      "['haue', 'ham', 'thou', 'shall', 'lord', 'come', 'king', 'enter', 'good', 'let', 'thy', 'caesar', 'vs', 'know', 'thee', 'would', 'brutus', 'like', 'vpon', 'bru', 'well', 'hath', 'selfe', 'man', 'may', 'macb', 'yet', 'heere', 'must', 'say', 'tis', 'th', 'loue', 'speake', 'make', 'giue', 'see', 'time', 'sir', 'night', 'one', 'st', 'cassi', 'ile', 'doe', 'hamlet', 'go', 'men', 'hor', 'vp']\n"
     ]
    }
   ],
   "source": [
    "top50Words = listOfSortedWords[0:50]             #top 50 words from the shakespeare list\n",
    "print('Top 50 words in Shakespeare: ')\n",
    "print(top50Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firefox.txt',\n",
       " 'grail.txt',\n",
       " 'overheard.txt',\n",
       " 'pirates.txt',\n",
       " 'singles.txt',\n",
       " 'wine.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_web =[]\n",
    "words_web.extend(nltk.corpus.webtext.words('firefox.txt'))\n",
    "words_web.extend(nltk.corpus.webtext.words('grail.txt'))\n",
    "words_web.extend(nltk.corpus.webtext.words('overheard.txt'))\n",
    "words_web.extend(nltk.corpus.webtext.words('pirates.txt'))\n",
    "words_web.extend(nltk.corpus.webtext.words('singles.txt'))\n",
    "words_web.extend(nltk.corpus.webtext.words('wine.txt'))\n",
    "#print(words_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_web = [''.join(c for c in s if c not in set(string.punctuation)) for s in words_web]   #remove all punctuation words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_web = [x for x in words_web if x]   #remove epmty string from list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_web_lower = []\n",
    "for word in words_web:\n",
    "    words_web_lower.append(word.lower())  #convert all the words in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_web_lower = [word for word in words_web_lower if word not in stopwords.words('english')] #remove all stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_web_freq = {}\n",
    "for word in words_web_lower:                    #loop through each word \n",
    "    if word in words_web_freq:\n",
    "        words_web_freq[word] += 1\n",
    "    else:\n",
    "        words_web_freq[word] = 1\n",
    "#print(words_ss_freq)\n",
    "listOfSortedWebWords = []                                                           \n",
    "listOfSortedWebWords = sorted(words_web_freq, key=words_web_freq.__getitem__ , reverse= True) #sorting words in descending order based on frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 words in Web Text: \n",
      "['girl', 'guy', '1', '2', 'like', 'man', 'know', 'woman', 'yeah', 'page', 'firefox', 'get', 'new', 'chick', 'one', 'oh', 'open', 'window', 'good', 'bookmarks', 'teen', 'well', 'firebird', 'cell', 'right', 'go', 'work', 'bar', 'menu', 'tab', 'lady', 'toolbar', 'boy', 'want', 'browser', 'think', 'jack', 'bookmark', 'old', 'really', 'going', 'download', 'url', 'back', 'time', 'black', 'manager', 'little', 'got', 'crash']\n"
     ]
    }
   ],
   "source": [
    "top50WebWords = listOfSortedWebWords[0:50]             #top 50 words from the web text\n",
    "print('Top 50 words in Web Text: ')\n",
    "print(top50WebWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unused_words = []\n",
    "unused_words = [word for word in words_ss_lower if word not in words_web_lower ]\n",
    "#print(unused_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unused_words_freq = {}\n",
    "for word in unused_words:              #loop through each word \n",
    "    if word in unused_words_freq:\n",
    "        unused_words_freq[word] += 1\n",
    "    else:\n",
    "        unused_words_freq[word] = 1\n",
    "#print(words_ss_freq)\n",
    "listOfUnusedWords = []                                                           \n",
    "listOfUnusedWords = sorted(unused_words_freq, key=unused_words_freq.__getitem__ , reverse= True) #sorting words in descending order based on frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 unused words: \n",
      "['haue', 'vpon', 'brutus', 'bru', 'hath']\n"
     ]
    }
   ],
   "source": [
    "top5UnusedWords = listOfUnusedWords[0:5]             #top 5 unused words\n",
    "print('Top 5 unused words: ')\n",
    "print(top5UnusedWords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
